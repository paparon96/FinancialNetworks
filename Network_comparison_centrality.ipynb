{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define own functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrality_norm_diff(candidate_dict,true_dict):\n",
    "    \n",
    "    \"\"\"Computes the difference of the centrality scores\n",
    "    given 2 dictionaries\"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    for key, val in candidate_dict.items():\n",
    "        score += np.linalg.norm(val-true_dict[key])\n",
    "        \n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_preprocessing(date,method,ts_type,dy_threshold):\n",
    "    \n",
    "    \"\"\"Import the network adjacency matrix from a .csv file, converts it into a networkx\n",
    "    diGraph object\"\"\"\n",
    "    \n",
    "    # Convert date to string\n",
    "    final_date_transformed = date.replace(\"-\",\"_\")\n",
    "    \n",
    "    \n",
    "    # Import file\n",
    "    filename = \"./Data/Estimated_networks/\" +\\\n",
    "                  method+\"_\"+ts_type+\"_\"+final_date_transformed+\".csv\"\n",
    "\n",
    "    if method == \"DY\":\n",
    "        network_matrix = np.genfromtxt(filename,\n",
    "                              delimiter=',',skip_header = 1,usecols = np.arange(1,11),\n",
    "                                   skip_footer=1)\n",
    "        \n",
    "        # Make the diagonal zero\n",
    "        np.fill_diagonal(network_matrix, 0)\n",
    "        \n",
    "        # Delete link if the edge weight is too small in case of DY\n",
    "        network_matrix[network_matrix<dy_threshold] = 0\n",
    "        \n",
    "        # Normalize values\n",
    "        network_matrix = network_matrix / 100\n",
    "        \n",
    "        print(network_matrix)\n",
    "        \n",
    "    else:\n",
    "        network_matrix = np.genfromtxt(filename,\n",
    "                              delimiter=',',skip_header = 1,usecols = np.arange(1,11))\n",
    "    \n",
    "    \n",
    "    # Convert it into networkX object\n",
    "    network = nx.from_numpy_matrix(network_matrix, create_using=nx.DiGraph)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrality_ranking_df(centrality_type,networks,varnames,cross_holding_network=None):\n",
    "    \n",
    "    \"\"\"Creates a dataframe with the sorted centrality of stocks\n",
    "    from different methods\"\"\"\n",
    "    \n",
    "    # Add the cross-holding network to the dictionary (optional)\n",
    "    if cross_holding_network is not None:\n",
    "        networks['CH'] = cross_holding_network\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Loop over different methods and their networks\n",
    "    for key,val in networks.items():\n",
    "        \n",
    "    \n",
    "        if centrality_type == \"katz-bonacich\":\n",
    "\n",
    "            centrality_dict = nx.katz_centrality(val)     \n",
    "            ticker_names = [varnames[k] for k, v in sorted(centrality_dict.items(),\n",
    "                                                     key=lambda item: item[1],reverse=True)]\n",
    "            \n",
    "        elif centrality_type == \"betweenness\":\n",
    "            \n",
    "            centrality_dict = nx.betweenness_centrality(val)\n",
    "            ticker_names = [varnames[k] for k, v in sorted(centrality_dict.items(),\n",
    "                                                     key=lambda item: item[1],reverse=True)]            \n",
    "        else:\n",
    "            ticker_names = None\n",
    "            \n",
    "        networks[key] = ticker_names\n",
    "\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(networks)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY BY DATE HERE TOO!\n",
    "CH = pd.read_excel('./Data/nasdaq_normalized_cross_holdings.xlsx')\n",
    "CH = np.array(CH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CH.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_names = CH[:,0]\n",
    "\n",
    "CH = CH[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH = np.asarray(CH,dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert it into networkX object\n",
    "CH_network = nx.from_numpy_matrix(CH, create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimated networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.1096 0.     0.     0.     0.1057 0.     0.     0.    ]\n",
      " [0.     0.1077 0.     0.     0.     0.     0.1055 0.     0.     0.    ]\n",
      " [0.     0.     0.1061 0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.1053 0.     0.     0.     0.1076 0.     0.     0.    ]\n",
      " [0.1076 0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.1074 0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.1064 0.     0.     0.     0.1104 0.     0.     0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "date = \"2020-06-30\"\n",
    "ts_type = \"return\"\n",
    "dy_threshold = 10.5\n",
    "\n",
    "# Iterables\n",
    "methods = ['NS','SPACE','GLASSO','DY','DAG']\n",
    "\n",
    "# Create dictionary to store the outputs\n",
    "networks = {}\n",
    "\n",
    "for method in methods:\n",
    "    \n",
    "    networks[method] = network_preprocessing(date,method,ts_type,dy_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality measure comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NS</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>GLASSO</th>\n",
       "      <th>DY</th>\n",
       "      <th>DAG</th>\n",
       "      <th>CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MS</td>\n",
       "      <td>BAC</td>\n",
       "      <td>MS</td>\n",
       "      <td>BAC</td>\n",
       "      <td>C</td>\n",
       "      <td>JPM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BAC</td>\n",
       "      <td>C</td>\n",
       "      <td>JPM</td>\n",
       "      <td>MS</td>\n",
       "      <td>JPM</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>JPM</td>\n",
       "      <td>BAC</td>\n",
       "      <td>JPM</td>\n",
       "      <td>WFC</td>\n",
       "      <td>BK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>JPM</td>\n",
       "      <td>MS</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>USB</td>\n",
       "      <td>BAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>USB</td>\n",
       "      <td>WFC</td>\n",
       "      <td>WFC</td>\n",
       "      <td>WFC</td>\n",
       "      <td>MS</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>TFC</td>\n",
       "      <td>TD</td>\n",
       "      <td>GS</td>\n",
       "      <td>GS</td>\n",
       "      <td>BAC</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>TD</td>\n",
       "      <td>USB</td>\n",
       "      <td>USB</td>\n",
       "      <td>USB</td>\n",
       "      <td>GS</td>\n",
       "      <td>WFC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>WFC</td>\n",
       "      <td>GS</td>\n",
       "      <td>TD</td>\n",
       "      <td>TD</td>\n",
       "      <td>TD</td>\n",
       "      <td>USB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>GS</td>\n",
       "      <td>BK</td>\n",
       "      <td>BK</td>\n",
       "      <td>BK</td>\n",
       "      <td>BK</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>BK</td>\n",
       "      <td>TFC</td>\n",
       "      <td>TFC</td>\n",
       "      <td>TFC</td>\n",
       "      <td>TFC</td>\n",
       "      <td>TFC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NS SPACE GLASSO   DY  DAG   CH\n",
       "0   MS   BAC     MS  BAC    C  JPM\n",
       "1  BAC     C    JPM   MS  JPM   GS\n",
       "2    C   JPM    BAC  JPM  WFC   BK\n",
       "3  JPM    MS      C    C  USB  BAC\n",
       "4  USB   WFC    WFC  WFC   MS   MS\n",
       "5  TFC    TD     GS   GS  BAC    C\n",
       "6   TD   USB    USB  USB   GS  WFC\n",
       "7  WFC    GS     TD   TD   TD  USB\n",
       "8   GS    BK     BK   BK   BK   TD\n",
       "9   BK   TFC    TFC  TFC  TFC  TFC"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parameters\n",
    "varnames = [\"MS\",\"JPM\",\"BAC\",\"C\",\"WFC\",\"GS\",\"USB\",\"TD\",\"BK\",\"TFC\"]\n",
    "centrality_type = \"betweenness\" #\"betweenness\" #\"katz-bonacich\"\n",
    "cross_holdings = True\n",
    "\n",
    "# Create centrality rankings\n",
    "if cross_holdings:\n",
    "    ranking_df = centrality_ranking_df(centrality_type,networks,varnames,\n",
    "                                      CH_network) # cross-holdings network is optional!\n",
    "else:\n",
    "    ranking_df = centrality_ranking_df(centrality_type,networks,varnames)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Inspect the dataframe\n",
    "display(ranking_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2020-03-05\"\n",
    "method = \"DY\"\n",
    "ts_type = \"return\"\n",
    "\n",
    "temp = network_preprocessing(date,method,ts_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "[[16.2  10.78 11.4  11.37  8.15 11.94  9.15  6.58  5.83  8.6 ]\n",
      " [ 9.54 14.49 12.07 11.52  8.41 10.36 10.66  6.6   6.58  9.76]\n",
      " [10.03 11.59 13.63 11.36  8.58 10.24 10.75  6.97  7.12  9.72]\n",
      " [10.19 11.81 11.98 14.38  8.42 10.59  9.53  7.    6.9   9.2 ]\n",
      " [ 9.01 10.51 11.13 10.14 16.98  9.01 10.71  6.33  6.19  9.99]\n",
      " [11.35 11.28 11.45 11.23  7.97 15.26  9.18  6.89  6.16  9.23]\n",
      " [ 8.9  11.47 11.83 10.11  8.94  9.12 15.3   6.43  6.87 11.03]\n",
      " [ 9.18  9.61 10.92  9.98  7.43  9.45  9.31 19.93  5.72  8.48]\n",
      " [ 7.39 10.   10.89 10.33  7.05  8.68  9.66  5.24 22.67  8.1 ]\n",
      " [ 8.74 11.03 11.31 10.18  9.03  9.58 11.85  6.46  5.88 15.95]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date = \"2020-03-05\"\n",
    "final_date_transformed = date.replace(\"-\",\"_\")\n",
    "method = \"DY\"\n",
    "ts_type = \"return\"\n",
    "\n",
    "filename = \"./Data/Estimated_networks/\" +\\\n",
    "                  method+\"_\"+ts_type+\"_\"+final_date_transformed+\".csv\"\n",
    "\n",
    "NE_estimated_matrix = np.genfromtxt(filename,\n",
    "                              delimiter=',',skip_header = 1,usecols = np.arange(1,11),\n",
    "                                   skip_footer=1)\n",
    "\n",
    "print(NE_estimated_matrix.shape)\n",
    "print(NE_estimated_matrix)\n",
    "\n",
    "CH_G = nx.from_numpy_matrix(NE_estimated_matrix, create_using=nx.DiGraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
